\section{Related Work}
\sys studies the link between data transformation synthesis and explanations. This builds from both data cleaning literature and explanation literature.

\stitle{Other Explanation Engines}
The most common type of explanations are \emph{correlative}. Given a view of the dataset (usually specified in SQL), they  identify predicates on a base tables that are most correlated with a selection of unexpected tuples in the view. This model was first proposed by Wu et al. in Scorpion for group-by aggregate visual data analytics, then extended by Roy et al. for more complex SQL queries~\cite{roy2015explaining}. Both Wu et al. and Roy et al., consider simple selections of output tuples as the complaint model. Chalamalla et al. studied more complex complaint models where complaints are specified in terms of integrity constraint violations~\cite{DBLP:conf/sigmod/ChalamallaIOP14}.
Finally, Bailis et al. consider this model in the context of streaming anomaly detection~\cite{bailis2016macrobase}. As the age-old axiom goes, correlation does not imply causation, and these systems can have counter-intuitive results when combined with dirty data. We argue that a stronger form of explanations can be generated in many cases where the system can actually suggest transformations (i.e., causation) to rectify anomalies. That said, this new problem is strictly harder and requires much more computation and is a best effort solution sacrificing provable guarantees.
This idea is highly related to View Conditioned Causality~\cite{meliou2011tracing}, and we consider what happens when you generalize the search problem to black box analyses.

\stitle{Data Cleaning Systems}
Data cleaning is nearly as old as the relational model~\cite{codd1970relational}, and numerous research and  commercial systems have been proposed to improve data cleaning efficiency and accuracy (see~\cite{rahm2000data} for a survey). 
There is certainly an overlap between \sys and data cleaning systems.
The key difference is \sys provides a suggestion of transformation rules rather than directly editing the database instance.
The closest neighbor in the data cleaning space is Falcon~\cite{he2016interactive}.
Falcon takes human example changes and translates them into transformation rules over the dataset.
We explore a higher level of supervision than Falcon, where the human simply defines a quality function that scores records as clean or dirty--not actually providing the explicit clean value.
Then, the system generates a sequence of transformation rules to best clean the dataset.

However, data cleaning systems provide a good baseline for \sys. We validate that the transformations found by \sys are sensible by comparing to data cleaning systems designed for similar classes of problems. 
For example, a quality function can be derived from integrity constraints
\sys is a much more flexible system that can handle transformations spanning from numerical operations to value replacement.
However, \sys does not provide a guarantee of constraint satisfaction and therefore cannot be compared in the same class of systems.

Despite this point, we believe that \sys is relevant to the recent advances in scalable data cleaning~\cite{wang1999sample, DBLP:journals/debu/KrishnanWFGKM015, khayyat2015bigdansing, altowim2014progressive}. Recent work has revealed {\it human-time}---finding and understanding errors, formulating desired characteristics of the data, writing and debugging the cleaning pipeline, and basic software engineering---as a dominant bottleneck in the entire data cleaning process~\cite{krishnan2016hilda}.  
\sys aims to address this bottleneck by using the quality function and transformation language as a flexible and expressive declarative interface to separate high level cleaning goals from how the goals are achieved.   

Machine learning has been widely used to improve the efficiency and/or reliability of data cleaning~\cite{DBLP:journals/pvldb/YakoutENOI11,yakout2013don,gokhale2014corleone}.
It is commonly used to predict an appropriate replacement attribute value for dirty records~\cite{yakout2013don}.
Increasingly, it is used in combination with crowd-sourcing to extrapolate patterns from smaller manually-cleaned samples~\cite{gokhale2014corleone,DBLP:journals/pvldb/YakoutENOI11} and to improve reliability of the automatic repairs~\cite{DBLP:journals/pvldb/YakoutENOI11}.
Concepts such as active learning can be leveraged to learn an accurate model with a minimal number of examples~\cite{DBLP:journals/pvldb/MozafariSFJM14}.
Recently, HoloClean~\cite{rekatsinas2017holoclean} uses probabilistic graphical models to combine multiple quality signals such as lookup tables and constraints to predict cell-level repairs.
Although related, \sys uses machine learning to steer the search process {\it away} from low quality candidate programs, rather than to propose ideal cleaning programs.  From this perspective, \sys can be extended to leverage ideas from existing work to steer the search process {\it towards} promising programs.  

Semantics about the downstream application can inform ways to clean the dataset ``just enough'' for the application.  
A large body of literature addresses relational queries over databases with errors by focusing on specific classes of queries~\cite{altwaijry2015query}, leveraging constraints over the input relation~\cite{2011Bertossi}, integration with crowd-sourcing~\cite{DBLP:conf/sigmod/BergmanMNT15}.   Recent work such as ActiveClean~\cite{DBLP:journals/pvldb/KrishnanWWFG16} extend this work to downstream machine learning applications, while Scorpion~\cite{DBLP:journals/pvldb/0002M13} uses the visualization-specified errors to search for approximate deletion transformations.   In this context, \sys can embed application-specific cleaning objects can be modeled within the quality function.  For instance, our quantitative cleaning experiments (\Cref{s:expquant}) simply embeds the model training and accuracy computation in the quality function. 
There has also been recent work on quantifying incompleteness in data quality metrics~\cite{chung2016data}.


\stitle{Program Synthesis in Data Transformation} A composable transformation language is the building block for systems like \sys that generate understandable programs.   Languages for data transformations have been well-studied, and include seminal works by Raman and Hellerstein~\cite{raman2001potter} for schema transformations and Galhardas et al.~\cite{DBLP:conf/vldb/GalhardasFSSS01} for declarative data cleaning. These ideas were later extended in the Wisteria project~\cite{DBLP:journals/pvldb/HaasKWF015} to parametrize the transformations to allow for learning and crowdsourcing.   Wrangler~\cite{wrangler} and Foofah~\cite{jin2017foofah} are text extraction and transformation systems that similarly formulate their problems as search over a language of text transformations, and develop specialized pruning rules to reduce the search space. Similarly, BlinkFill uses programming-by-example to generate candidate macros in spreadsheets~\cite{singh2016blinkfill}. In this work, we do not consider the programming-by-demonstrations setting. Our interaction model consists of application interaction which can be turned into a scoring function on base data--again, not giving explicit supervision of what values will optimize the scoring function.


